{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting Minutes Generator\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "### Background\n",
    "Traditional meeting documentation is time-consuming and often misses critical details. Manual transcription of meetings can take up to 3-4 times the length of the meeting itself, leading to:\n",
    "- Reduced productivity\n",
    "- Inconsistent documentation\n",
    "- Missing important action items\n",
    "- Difficulty in knowledge sharing\n",
    "\n",
    "### Objective\n",
    "Create an automated meeting minutes generator that will:\n",
    "1. Transcribe audio recordings to text using state-of-the-art speech recognition models\n",
    "2. Extract key information including:\n",
    "   - Main discussion points\n",
    "   - Action items and assignments\n",
    "   - Decisions made\n",
    "   - Follow-up tasks\n",
    "3. Generate structured, easily readable meeting minutes\n",
    "4. Support multiple audio formats and meeting types\n",
    "\n",
    "### Technical Requirements\n",
    "- Speech-to-text conversion using OpenAI Whisper or AssemblyAI\n",
    "- Natural Language Processing for information extraction\n",
    "- Secure handling of sensitive meeting data\n",
    "- Support for multiple speakers (diarization)\n",
    "- Export functionality to common formats (PDF, DOCX, etc.)\n",
    "\n",
    "### Success Metrics\n",
    "- Transcription accuracy > 95%\n",
    "- Processing time < 0.5x meeting duration\n",
    "- Correct identification of key points and action items\n",
    "- User satisfaction with generated minutes format\n",
    "\n",
    "### Scope\n",
    "Phase 1:\n",
    "- Audio file upload and transcription\n",
    "- Basic text processing and formatting\n",
    "- Simple export functionality\n",
    "\n",
    "Future Phases:\n",
    "- Real-time transcription\n",
    "- Speaker identification\n",
    "- Integration with calendar and task management systems\n",
    "- Custom templates for different meeting types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeetingTranscriber:\n",
    "    def __init__(self):\n",
    "        self.client = client\n",
    "        \n",
    "    def transcribe_audio(self, audio_path: str) -> dict:\n",
    "        \"\"\"\n",
    "        Transcribe audio file using OpenAI's Whisper model\n",
    "        \n",
    "        Args:\n",
    "            audio_path (str): Path to the audio file\n",
    "            \n",
    "        Returns:\n",
    "            dict: Transcription result containing text and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(audio_path, \"rb\") as audio_file:\n",
    "                transcript = self.client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=audio_file,\n",
    "                    response_format=\"verbose_json\"\n",
    "                )\n",
    "            \n",
    "            return {\n",
    "                'text': transcript.text,\n",
    "                'timestamp': datetime.datetime.now().isoformat(),\n",
    "                'duration': self._get_audio_duration(audio_path),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'text': None,\n",
    "                'timestamp': datetime.datetime.now().isoformat(),\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    def _get_audio_duration(self, audio_path: str) -> float:\n",
    "        \"\"\"Get duration of audio file in seconds\"\"\"\n",
    "        audio_info = sf.info(audio_path)\n",
    "        return audio_info.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    transcriber = MeetingTranscriber()\n",
    "\n",
    "    audio_data, sample_rate = sf.read(\"denver.mp3\")\n",
    "    audio_data = audio_data[:15 * 60 * sample_rate]\n",
    "    sf.write(\"denver_audio_trimmed.mp3\", audio_data, sample_rate)\n",
    "\n",
    "        # transcribe the audio file\n",
    "    result = transcriber.transcribe_audio(\"denver_audio_trimmed.mp3\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Transcription completed! Duration: {result['duration']:.2f} seconds\")\n",
    "    else:\n",
    "        print(f\"Error during transcription: {result['error']}\")\n",
    "\n",
    "    # system prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are a highly skilled AI assistant tasked with generating concise and informative meeting minutes from a provided meeting transcript. \n",
    "    Extract key elements like the meeting title, date and time, attendees, absentees, agenda items, decisions made, action items, and next steps.\n",
    "    Structure the minutes with a header, attendee list, agenda items and discussion summaries, decisions, action items with assigned individuals and \n",
    "    deadlines, and next steps. Write in a professional tone, using clear and concise language, and maintain a neutral and objective perspective. \n",
    "    Focus on brevity, summarizing key information without unnecessary detail, and proofread carefully to ensure the minutes are free of errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    # user prompt\n",
    "    user_prompt = f\"\"\"\n",
    "    Here is the transcript of the meeting: `{result['text']}`\n",
    "    \"\"\"\n",
    "\n",
    "    messages_chat = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    # generate the meeting minutes\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages_chat\n",
    "    )\n",
    "    \n",
    "    # print the response\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bites and bytes package to do quantization\n",
    "from bitsandbytes import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "# quantization config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_quant_storage=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_storage_quant_type=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# model\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(model_id, quantization=quant_config, auto_device=True, torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "# generate the meeting minutes\n",
    "input_ids = tokenizer.apply_chat_template(messages_chat, tokenize=False, add_bos=True)\n",
    "output = quantized_model.generate(input_ids, max_length=1000)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
